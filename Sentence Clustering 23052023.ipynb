{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\scipy\\__init__.py:173: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os, re, time\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from ftfy import fix_text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads S800 Dataset\n",
    "\n",
    "s800 = pd.read_csv('data/input/S800/S800.tsv',sep='\\t',header=None)\n",
    "s800_x = s800[[0,4]].drop_duplicates(subset=4).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads other species datasets\n",
    "\n",
    "speciesdct = {}\n",
    "for file in os.listdir('data/input/'):\n",
    "    if file.endswith('.PubTator'):\n",
    "        with open('data/input/' + file) as f:\n",
    "            lines = [line.rstrip('\\n') for line in f]\n",
    "            for line in lines:\n",
    "                if ((len(line.split('\\t')) > 1)):\n",
    "                    if((line.split('\\t')[4] == 'Species')):\n",
    "                         speciesdct[line.split('\\t')[3]] = line.split('\\t')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructs the train test\n",
    "\n",
    "s800 = s800_x.rename(columns={4:'index'})\n",
    "spec = pd.DataFrame.from_dict(speciesdct, orient='index').reset_index()\n",
    "final = pd.concat([s800, spec])\n",
    "final = final.drop_duplicates(subset=['index']).reset_index(drop=True)\n",
    "train = final.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C. damasonium</td>\n",
       "      <td>Plasmodium falciparum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paracercomonas marina</td>\n",
       "      <td>P falciparum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paulinella chromatophora</td>\n",
       "      <td>Candida guilliermondii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filoreta japonica</td>\n",
       "      <td>yeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cronartium quercuum f.sp. fusiforme</td>\n",
       "      <td>C. guilliermondii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Chironomus thummi</td>\n",
       "      <td>Callosobruchus maculatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Fremyella diplosiphon</td>\n",
       "      <td>Chlamydomonas reinhardtii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Influenza A H1N1</td>\n",
       "      <td>Casaurina glauca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Picea glauca (Moench) Voss</td>\n",
       "      <td>Datisca glomerata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Human adenoviruses</td>\n",
       "      <td>S. meliloti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>904 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      S1                         S2\n",
       "0                          C. damasonium      Plasmodium falciparum\n",
       "1                  Paracercomonas marina               P falciparum\n",
       "2               Paulinella chromatophora     Candida guilliermondii\n",
       "3                      Filoreta japonica                      yeast\n",
       "4    Cronartium quercuum f.sp. fusiforme          C. guilliermondii\n",
       "..                                   ...                        ...\n",
       "899                    Chironomus thummi   Callosobruchus maculatus\n",
       "900                Fremyella diplosiphon  Chlamydomonas reinhardtii\n",
       "901                     Influenza A H1N1           Casaurina glauca\n",
       "902           Picea glauca (Moench) Voss          Datisca glomerata\n",
       "903                   Human adenoviruses                S. meliloti\n",
       "\n",
       "[904 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.concat([final['index'].tail(904).reset_index(drop=True).rename('S1'), final['index'].head(904).rename('S2')],axis=1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match n x n\n",
    "\n",
    "train_index = train['index']\n",
    "s = pd.DataFrame(list(product(train_index, train_index)), columns=['S1', 'S2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=2):\n",
    "    string = str(string)\n",
    "\n",
    "    # Fixes text for any possible decoding issues\n",
    "    string = fix_text(string)\n",
    "\n",
    "    # Removes non ascii chars\n",
    "    string = string.lower()\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "\n",
    "    # Cleaning unrelevant characters\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title()\n",
    "    string = re.sub(' +',' ',string).strip()\n",
    "    string = ' '+ string +' '\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tfidf = vectorizer.fit_transform(s['S1'].astype('U'))\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<90000x633 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1503000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearestN(query):\n",
    "    # Returns a number document-term matrix\n",
    "    queryTFIDF_ = vectorizer.transform(query) \n",
    "    distances, _ = nbrs.kneighbors(queryTFIDF_)\n",
    "    return distances, _\n",
    "\n",
    "start_time = time.time()\n",
    "distances, _ = getNearestN(s['S2'].astype('U'))\n",
    "t = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.insert(2,'Distance',distances, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied sklearn's MinMaxScaler to scale the distances between the range of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First scaled the distance by using min max scaler\n",
    "\n",
    "x = s['Distance'].values.reshape(-1,1)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scaled_conf = pd.Series(min_max_scaler.fit_transform(x).reshape(-1))\n",
    "s.insert(3, \"Scaled_Distance\", scaled_conf, True)\n",
    "s['Scaled_Distance'] = s['Scaled_Distance'].apply(lambda col: round(col,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = 1 - s['Scaled_Distance']\n",
    "s.insert(4, \"Probability\", proba, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.Probability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s[s['Probability']>0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
